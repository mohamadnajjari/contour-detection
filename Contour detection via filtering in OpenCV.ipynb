{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests \n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch an image from a URL, This line sends an HTTP GET request to the URL\n",
    "# a status code of 200 in HTTP response means \"OK\" or \"Success.\"\n",
    "response = requests.get('https://i.stack.imgur.com/ukOkD.jpg')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.content contains the raw binary content of the image.\n",
    "# BytesIO is a class in the io module that provides a binary stream interface to an in-memory buffer.\n",
    "# The Image.open function from the Python Imaging Library (PIL) is used to open the image. \n",
    "# The Image.open takes the binary stream created from the image content as an argument, effectively loading the image into memory.\n",
    "# Image.open from the Pillow library (PIL), the default mode for reading the image is 'RGB'\n",
    "# The resulting image, which is initially a PIL (Pillow) Image object, is converted to a NumPy array using np.asarray\n",
    "# np.asarray conversion allows for easier manipulation and processing of the image using NumPy and other libraries like OpenCV.\n",
    "image = np.asarray(Image.open(BytesIO(response.content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.cvtColor is a function in OpenCV used for color space conversion.\n",
    "# OpenCV typically represents images in BGR order, whereas many other libraries (including PIL/Pillow) use RGB order.\n",
    "# cv.COLOR_BGR2GRAY: This constant indicates the color space conversion from BGR (Blue, Green, Red) to grayscale.\n",
    "image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobelx defines a 3x3 convolution kernel matrix for horizontal edge detection. \n",
    "# sobely defines a 3x3 convolution kernel matrix for vertical edge detection. \n",
    "# This specific kernels are known as the Sobel kernels for detecting horizontal and vertical edges in an image.\n",
    "# In image processing, convolution is a mathematical operation that combines two functions to produce a third.\n",
    "# convolution involves sliding a small matrix (kernel) over the image and computing the weighted sum of the pixel values at each position.\n",
    "sobelx = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
    "sobely = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.filter2D is used for 2D convolution, which involves sliding a kernel matrix over the image and computing the weighted sum of pixel values at each position.\n",
    "# vertical_edge variable contains the output of the convolution operation.this operation emphasizes the horizontal edges in the image, highlighting areas where there is a significant intensity change from left to right.\n",
    "# hotizontal_edge variable contains the output of the convolution operation.this operation emphasizes the vertical edges in the image, highlighting areas where there is a significant intensity change from top to bottom.\n",
    "# second argument is ddepth which is Depth of the output image; if it is set to -1, the output image will have the same depth as the input image.\n",
    "vertical_edge = cv.filter2D(image_gray, -1, sobelx)\n",
    "horizontal_edge = cv.filter2D(image_gray, -1, sobely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cv.adaptiveThreshold function calculates the threshold for small regions of the image (defined by the neighborhood size) and applies different thresholds to different regions based on their local characteristics. \n",
    "# cv.ADAPTIVE_THRESH_MEAN_C: specifies the method for thresholding. It uses the mean of the neighborhood area.\n",
    "# cv.THRESH_BINARY: The type of thresholding applied after the adaptive thresholding.\n",
    "# 11: Size of the pixel neighborhood used to calculate the threshold value. It must be an odd number.\n",
    "# 2: A constant subtracted from the mean or weighted mean (depending on the adaptive method). This can be used to fine-tune the threshold.\n",
    "# After this operation, image_adth should contain the resulting binary image after adaptive thresholding. Pixels with intensity values above the threshold will be set to the maximum value (255), and pixels below the threshold will be set to 0.\n",
    "image_adth = cv.adaptiveThreshold(vertical_edge, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 9,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median filtering is a type of nonlinear filtering that replaces the pixel value in the center of the neighborhood with the median value of all the pixels in the neighborhood.\n",
    "# Median filtering operation is effective in reducing salt-and-pepper noise while preserving edges.\n",
    "# 25: The size of the kernel or the neighborhood window. The kernel size must be a positive odd integer.\n",
    "# The larger the kernel size, the stronger the smoothing effect, but it may also result in more blurring.\n",
    "image_blur = cv.medianBlur(image_adth, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: The threshold value used for comparison. In this case, it's set to 0, but since Otsu's method is used (cv.THRESH_OTSU), this value is not critical.\n",
    "# 255: The maximum pixel value that can be assigned to the output pixels. \n",
    "# cv.THRESH_BINARY specifies that pixels with intensities above the threshold will take the value 255, and pixels below the threshold will take the value 0.\n",
    "# cv.THRESH_OTSU flag indicates that the optimal threshold value should be determined automatically using Otsu's method.\n",
    "# ret: The computed threshold value. In this case, it's the threshold determined by Otsu's method\n",
    "# after this operation, image_gray should contain a binary image where the threshold is automatically determined using Otsu's method. \n",
    "ret, image_gray = cv.threshold(image_blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour detection function\n",
    "def function(image_gray,image, horizontal_edge):\n",
    "\n",
    "    # cv.findContours function in OpenCV finds contours in the grayscale image\n",
    "    # cv.RETR_TREE: The contour retrieval mode. This mode retrieves all of the contours and reconstructs a full hierarchy of nested contours. Contours are organized as a tree structure.\n",
    "    # cv.CHAIN_APPROX_SIMPLE: The contour approximation method. This method compresses horizontal, vertical, and diagonal segments and leaves only their end points. For example, an up-right rectangular contour is encoded with only four points.\n",
    "    # contours: A list of contours found in the image. Each contour is represented as a list of points.\n",
    "    # _: The hierarchy of contours. In this case, it's not being used, so it is assigned to an underscore to indicate that it is not needed.\n",
    "    contours, _ = cv.findContours(image_gray, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initializes an empty list to store the contours that meet the specified area criteria.\n",
    "    new_counters = []\n",
    "\n",
    "    # c represents a contour and i is its index in the list.\n",
    "    # cv.contourArea(c): Calculates the area of the current contour\n",
    "    # if statement Checks whether the area of the current contour falls within the specified range\n",
    "    for i, c in enumerate(contours):\n",
    "        area = cv.contourArea(c)\n",
    "        if area>3500 and area<6000:\n",
    "            new_counters.append(c)\n",
    "            \n",
    "    # contours_poly: stores the approximated polygons for each contour, Each element in the list corresponds to a contour, and initially, it is set to None. After processing, it will contain the approximated polygon for the corresponding contour.    \n",
    "    # boundRect: This list will store the bounding rectangles for each contour.\n",
    "    # lines: This list will store boolean values indicating whether each contour is considered a \"line\", all elements are initially set to False. Later, some elements may be set to True\n",
    "    contours_poly = [None]*len(new_counters)\n",
    "    boundRect = [None]*len(new_counters)\n",
    "    lines = [False]*len(new_counters)\n",
    "\n",
    "\n",
    "    for i, c in enumerate(new_counters):\n",
    "\n",
    "        # Calculates the perimeter of the contour c.\n",
    "        epsilon = 0.01 * cv.arcLength(c, True) \n",
    "\n",
    "        # Approximates the contour c with a polygon, where epsilon is the approximation accuracy. \n",
    "        contours_poly[i] = cv.approxPolyDP(c, epsilon, True)\n",
    "\n",
    "        # Calculates the bounding rectangle for the approximated polygon \n",
    "        boundRect[i] = cv.boundingRect(contours_poly[i])\n",
    "        \n",
    "        x, y, width, height = boundRect[i]\n",
    "        \n",
    "        # Extracts a region from the horizontal_edge image based on the bounding rectangle.\n",
    "        extracted_region = horizontal_edge[ y:y+height, x:x+width]\n",
    "        _, extracted_region = cv.threshold(extracted_region, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "        # Finds contours in the thresholded extracted region \n",
    "        contours, _ = cv.findContours(extracted_region, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Checks the area of each contour (area > 50). If the area is above the specified threshold, it sets the corresponding element in the lines list to True.\n",
    "        for _, cc in enumerate(contours):\n",
    "            area = cv.contourArea(cc)\n",
    "            print(area)\n",
    "            if area>50:# and area<6000:\n",
    "                lines[i] = True\n",
    "                \n",
    "    for i in range(len(new_counters)):\n",
    "\n",
    "        # Define color values for red and green.\n",
    "        red = (0, 0, 255)\n",
    "        green = (0, 255, 0)\n",
    "\n",
    "        # Checks whether the current contour is considered a \"line\" based on the lines list. If it is a line, it draws a green rectangle around the region of interest:\n",
    "        # These rectangles are drawn on the original image to visually represent the identified regions\n",
    "        # The green rectangles indicate regions identified as lines, while the red rectangles indicate other regions\n",
    "        # The cv.rectangle function is used to draw rectangles on the image, and the coordinates of the rectangles are determined by the bounding rectangles (boundRect).\n",
    "        if lines[i]:\n",
    "            cv.rectangle(image, (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "            (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), green, 2)\n",
    "\n",
    "        # If it is not a line, it draws a red rectangle around the region of interest:   \n",
    "        else:\n",
    "            cv.rectangle(image, (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "            (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), red, 2)\n",
    "                \n",
    "    cv.imshow('Contours', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "14.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "3.0\n",
      "0.5\n",
      "6.5\n",
      "4.5\n",
      "0.0\n",
      "1.0\n",
      "30.0\n",
      "11.0\n",
      "14.5\n",
      "0.0\n",
      "4.5\n",
      "4.0\n",
      "1.0\n",
      "0.0\n",
      "87.0\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.5\n",
      "5.5\n",
      "0.0\n",
      "22.0\n",
      "0.0\n",
      "4.0\n",
      "17.0\n",
      "10.5\n",
      "1.0\n",
      "5.5\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "70.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "23.5\n",
      "18.5\n",
      "10.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "4.0\n",
      "4.0\n",
      "9.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "37.0\n",
      "3.0\n",
      "6.5\n",
      "2.5\n",
      "0.0\n",
      "2.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "77.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "1.5\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.0\n",
      "0.0\n",
      "32.5\n",
      "0.0\n",
      "7.0\n",
      "11.5\n",
      "20.0\n",
      "1.5\n",
      "2.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "6.5\n",
      "0.0\n",
      "10.5\n",
      "0.0\n",
      "28.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "111.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.5\n",
      "5.5\n",
      "9.0\n",
      "40.5\n",
      "52.5\n",
      "6.5\n",
      "0.0\n",
      "0.5\n",
      "3.5\n",
      "14.0\n",
      "0.0\n",
      "1.0\n",
      "7.0\n",
      "1.0\n",
      "1.0\n",
      "2.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.5\n",
      "0.0\n",
      "0.5\n",
      "2.5\n",
      "0.0\n",
      "0.0\n",
      "2.5\n",
      "0.0\n",
      "0.5\n",
      "5.0\n",
      "0.0\n",
      "3.5\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "29.5\n",
      "0.5\n",
      "2.0\n",
      "5.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "23.0\n",
      "1.0\n",
      "19.5\n",
      "6.0\n",
      "51.0\n",
      "2.5\n",
      "87.0\n",
      "2.5\n",
      "0.0\n",
      "10.0\n",
      "113.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# creating a graphical user interface (GUI) using OpenCV to display an image (image)\n",
    "# Creates a window with the name 'Source' and show originaal image.\n",
    "window = 'Source'\n",
    "cv.namedWindow(window)\n",
    "cv.imshow(window, image)\n",
    "\n",
    "# Calls the function\n",
    "function(image_gray,image,horizontal_edge)\n",
    "\n",
    "# Waits indefinitely for a key press. The program will continue running until a key is pressed\n",
    "cv.waitKey(0) \n",
    "\n",
    "#  Closes all OpenCV windows.\n",
    "cv.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
